### Running the tracking reconstruction from scratch for user generated MC  (CMSSW_7_1_0)

Much credit goes towards Matti Kortelainen and Kevin Stenson for this recipe.  Please note: This has only been validated for CMSSW_7_1_0 and above.  

I have included configuration file ```recoTrack_MC_710_cfg.py``` generated from cmsDriver.py that will run the tracking reconstruction given some initial MC sample.  This (presumably) works for any already generated MC sample that has the necessary steps listed below. The initial MC sample can generated in the following way:

```
cmsDriver.py <Sample-cfi.py-file> -s GEN,SIM,DIGI,L1,DIGI2RAW,HLT --conditions auto:startup --eventcontent FEVTDEBUGHLT  -n <number of events> --no_exec
```

The ```<Sample-cfi.py-file>``` is the configuration file for a generic MC sample, where a plethora can be found in github:
https://github.com/USER/cmssw/tree/CMSSW_X_Y_Z/Configuration/Generator/python

I choose TTbar at 8TeV for starters, as it seems to be the consensus benchmark for any sort of tracking performance analysis, i.e. ```TTbar_8TeV_cfi.py```. 

After running cmsDriver once, it will generate a python configuration file that then can be run with cmsRun to generate the MC.  To run, simply do: ```cmsRun <auto-generated-cfg.py-file>```.  This will create MC generated ROOT file with the path and name given by the autogenerated config file (which you can change yourself before running by editting the config file).  If you would rather just jump straight to generating and not create the python config file, drop the "--no_exec" option. 

From here, you will need to go into the ```recoTrack_MC_710_cfg.py``` and make some small changes. Indicate the number of events you wish to run over, -1 being the default for all events.  You will need to edit the filename and path to the file to match the ROOT output from the generation.  The string ```'file:<file.root>'``` indicates that the file is located locally.  If you wish to pull from anywhere using xrootd, you need the regional redirector: 

```python
process.source = cms.Source("PoolSource",
                            fileNames = cms.untracked.vstring(
                            'root://xrootd.unl.edu//<path-to-dataset-from-DAS>
                            )
```

Notice that the string ```file:``` is removed, as you are accessing data remotely.  Use DAS to obtain the full path to the directory of the dataset, starting with ```/store/```.

To run, simply type ```cmsRun recoTrack_MC_710_cfg.py```. 

If you would rather generate the tracking reco config file yourself instead of using ```recoTrack_MC_710_cfg.py```, you will need to run cmsDriver.py again with the MC root file produced in the initial MC generation, i.e. ```<path-to-input-root-file>``` in the step below.  Now do the following:

```
cmsDriver.py step3 -s RAW2DIGI,L1Reco,RECO --conditions auto:startup --datatier GEN-SIM-RECO --eventcontent FEVTDEBUGHLT -n <number-of-events> --filein <path-to-input-root-file> --no_exec
```

This will auto generate a python configuration file, ```<auto-gen-RECO-cfg.py-file>```.  You will now have to make some edits to the generated python config file.  Append the end of the document with the following lines:

```python
process.myreconstruction = cms.Sequence(process.trackerlocalreco+
                                        process.muonlocalreco+process.calolocalreco+process.offlineBeamSpot+
                                        process.MeasurementTrackerEvent+
                                        process.siPixelClusterShapeCache+
                                        process.standalonemuontracking+process.recopixelvertexing+process.iterTracking+
                                        process.electronSeedsSeq+process.doAlldEdXEstimators+process.trackExtrapolator+
                                        process.vertexreco+process.logErrorHarvester
                                        )
process.reconstruction_step = cms.Path(process.myreconstruction)
```

Additionally, you will need delete/comment out the first instance of ```process.reconstruction_step = cms.Path()``` and then move the process.schedule line to the end of the python file.  You may also want to change the name of the output root file.  After all the edits have been made, execute with:

```cmsRun <auto-gen-RECO-cfg.py-file>```

### Run Reco and get average time spent in each module per event with relVal samples for CMSSW_5_3_13 on the LPCCAF

To run over lots of samples to obtain timing info, we will need to submit jobs to CRAB (version 2 at the moment) on the LPCCAF, the condor cluster for the CMS LPC T3, which is NOT grid accesible.  To begin, ssh into cmslpc-sl5.  

The timing information for each module in the reconstruction is kept in recoTrack_MC_5313_cfg.py:
```python
process.options = cms.untracked.PSet(wantSummary = cms.untracked.bool(True))
```

We will be using relVal samples (on the order of ~10k events).  To find an approriate set, type in DAS:  

```
dataset=/RelValTTbar*/*CMSSW_5_3_13*/*
```

This will return a set of relval samples (hopefully) still valid.  For this example, I used: ```/RelValTTbar/CMSSW_5_3_13_patch3-START53_LV3_Feb24-v1/GEN-SIM-DIGI-RAW-HLTDEBUG```.  From here, modify the crab.cfg file appropriately to match the dataset you are running over under datasetpath.  CRAB will ignore the input files and max number of events in your python file, so make sure to set it in crab.cfg.  Currently, crab.cfg fill is set to write out the output root files to my storage element at the LPC. Feel free to change this as you like.  To write your output root files locally, remove the ```user_remote_dir``` option and set ```return_data = 1```, and ```copy_data = 0```.  Name the output whatever you would like.  ```-1``` in ```total_number_of_events``` will yield the max amount of events to run over in the dataset.  ```ui_working_dir``` is where the stdout (and stderr) will go for each CRAB job.  Note: CRAB places both stdout and stderr in single CMSSW_$jobnumber.stdout file. This is where all the timing stuff is spit out to using CRAB.

To run on the LPC T3, you must set the scheduler to ```condor``` and then submit to CRAB while ssh into LPC.  
To run the CRAB jobs, do the following after logging in (assuming you run t/csh you already have a working area with 5_3_13, see here for how to set up working directory at LPC: https://twiki.cern.ch/twiki/bin/viewauth/CMS/SWGuideCMSDataAnalysisSchoolPreExerciseFirstSet#Exercise_3_Setup_a_release_area):

```
source /uscmst1/prod/sw/cms/cshrc prod
cd <WorkingArea/CMSSW_5_3_13/src/whereverYouSavedTheConfigFiles>
source /uscmst1/prod/grid/gLite_SL5.csh; voms-proxy-init -voms cms; source /uscmst1/prod/grid/CRAB/crab.csh
crab -create
crab -submit -c <ui_working_dir>  --> use -c if you specified a local working directory 
```

Check every now and then to see if the jobs completed with ```crab -status -c <ui_working_dir>```.  After the jobs have completed, you will need to retrieve the stdout files with:

```
crab -getoutput -c <ui_working_dir>
```

Once you have the stdout files, you can get the time profiling with: ```./getTimingModules.sh <input_dir> <out-dir>```

Make sure to specify the right path for the input stdout files (```<ui_working_dir>/res/``` -- res is where the stdouts are sitting)!  The output will be a .csv file for each iteration in the reco, containing the average time per event spent in a given module (in that particular iterative step) for each CRAB job.  Both CPU and wall clock time are recorded for each module.  The results for each module are then averaged over these csv files to produce an average module time per event for all events, stored in the averages csv files.  The total csv files then compute the total average time it takes for each iteration to complete for the dataset.  These files are located in ```<out-dir>```, specified by the user.

### Customize the iterations for Tracking using recoTrack_MC_5313_cfg.py

With all the modules imported in the python file (just copied from RecoTracker.IterativeTracking.iterativeTk_cff), you can set your own steps for the iterative tracking (here, in process.myiterTracking).  Note: the steps are dependent on each other, so if you remove step N and keep N+1, it will crash!  To prevent this from happening, you will need to go to the cff file for each iteration, and look and see what it does to remove clusters from the previous iteration (defined first in ${iteration}StepClusters).  You will want to change the configuration in your cfg file to match the N-1 cluster remover.  

For example, say you want to skip the LowPtTripletStep, going from InitialStep to PixelPairStep, add thie following to the ```recoTrack_MC_5313_cfg.py``` file...

```python
# NEW CLUSTERS (remove previously used clusters)
PixelPairStepClusters = cms.EDProducer("TrackClusterRemover",
    clusterLessSolution= cms.bool(True),
    trajectories = cms.InputTag("initialStepTracks"),
    overrideTrkQuals = cms.InputTag('initialStepSelector','initialStep'),
    TrackQuality = cms.string('highPurity'),
    minNumberOfLayersWithMeasBeforeFiltering = cms.int32(0),
    pixelClusters = cms.InputTag("siPixelClusters"),
    stripClusters = cms.InputTag("siStripClusters"),
    Common = cms.PSet(
       maxChi2 = cms.double(9.0)
    )
)
```

If you notice, all I did was copy the LowPtTripletStepClusters to this file (from RecoTracker.IterativeTracking.LowPtTripletStep_cff) and renamed the variable as PixelPairStepClusters to accurately reflect the change in the tracking.  You can of course mix and match modules, just make sure to remove the right clusters if you do this!

N.B.
DO NOT just remove the module from the ${iteration}Step sequence... this will cause that N+1 iteration to use the same clusters as the N-1 iteration.  THIS IS BAD.

You can also mess with the parameters for the finding and fiitng by imorting the right files and changing the values appropriately (by changing the appropriate modules in ${iteration}Step_cff). 


### Changes for running own user MC on CMSSW_5_3_13 using recoTrack_MC_710_cfg.py

Minor changes need to be made from the above recipe.  The first is after running cmsDriver to produce a python file for first generating the MC, you need to edit line 26 to the following: 
```
process.load('HLTrigger.Configuration.HLT_7E33v2_cff')         
```
For whatever reason, cmsDriver chooses the wrong HLT menu (GRun), and needs 7E33v2 instead in order to process the HLT step.

After generating the MC with cmsRun, in ```recoTrack_MC_710_cfg.py```,  process.myconstruction needs to have 
```
process.MeasurementTrackerEvent+process.siPixelClusterShapeCache+
```
commented out, as this is something for post 7_1_0.


### Rerunning the tracking reconstruction with small RelVal Samples

I have also included a small python configuration file to **rerun** the tracking reconstruction.  It works for CMSSW_7_1_0_pre8, using a small RelVal ttbar sample that is currently available.  The goal will obviously be to move to something more stable, but this works fine if you do not want to go through the hassle of generating your own MC sample. 

So after setting up the release area, all you have to do is: ```cmsRun reRecoTrk_cfg.py```


The instructions (and subsequent modifications) came from the following question on CMS HyperNews:
https://hypernews.cern.ch/HyperNews/CMS/get/recoTracking/1438.html

